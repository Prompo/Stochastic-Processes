{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUCLr2dsyWQ"
      },
      "source": [
        "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
        "\n",
        "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab9/Lab_theory.pdf\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που ζητάει το διαχωρισμό ονομάτων DNS σε <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
        "\n",
        "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος www.ntua.gr είναι το <i>www</i>, ενώ το prefix του ονόματος dolly.netmode.ece.ntua.gr είναι το <i>dolly</i>.</p>\n",
        "\n",
        "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/invalid_training.txt\">invalid_training.txt</a>). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
        "\n",
        "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
        "<ul>\n",
        "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
        "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
        "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
        "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
        "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
        "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
        "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
        "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
        "</ul>\n",
        "\n",
        "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
        "<ul>\n",
        "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
        "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab9/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8LltO9Rsm0eZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc12deaf-eef9-457c-f333-876c4bf3d21d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_plJQ1Z2i5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e663f7b-fbb3-48ec-cbe6-13206c68f684"
      },
      "source": [
        "%%time\n",
        "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
        "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
        "\n",
        "def load_file(file_name):\n",
        "    fd = open(file_name, \"r\")\n",
        "    my_set = set()\n",
        "    for prefix in fd:\n",
        "        prefix = prefix.rstrip()\n",
        "        my_set.add(prefix)\n",
        "    return my_set\n",
        "\n",
        "def calculate_probabilities(dataset):\n",
        "    stats = dict()\n",
        "    for index in range(0, 7):\n",
        "        stats[index] = dict()\n",
        "    for prefix in dataset:\n",
        "        features = handle_name(prefix)\n",
        "        for index in range(0, 7):\n",
        "            try:\n",
        "                stats[index][features[index]] += 1\n",
        "            except:\n",
        "                stats[index][features[index]] = 1\n",
        "\n",
        "    dataset_size = len(dataset)\n",
        "    for index in range(0, 7):\n",
        "        for key in stats[index]:\n",
        "            stats[index][key] /= dataset_size\n",
        "    return stats\n",
        "\n",
        "def handle_name(prefix):\n",
        "    total_length = len(prefix)\n",
        "    total_digits, max_numeric_sequence = numeric(prefix)\n",
        "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
        "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
        "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
        "\n",
        "def vowels(prefix):\n",
        "    total_vowels = 0\n",
        "    vowels_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
        "            total_vowels += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            vowels_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    vowels_sequence.append(current_sequence)\n",
        "    max_vowels_sequence = max(vowels_sequence)\n",
        "    return total_vowels, max_vowels_sequence\n",
        "\n",
        "def consonants(prefix):\n",
        "    total_consonants = 0\n",
        "    consonants_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
        "            total_consonants += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            consonants_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    consonants_sequence.append(current_sequence)\n",
        "    max_consonants_sequence = max(consonants_sequence)\n",
        "    return total_consonants, max_consonants_sequence\n",
        "\n",
        "def numeric(prefix):\n",
        "    total_digits = 0\n",
        "    numeric_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char.isdigit() == True:\n",
        "            total_digits += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            numeric_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    numeric_sequence.append(current_sequence)\n",
        "    max_numeric_sequence = max(numeric_sequence)\n",
        "    return total_digits, max_numeric_sequence\n",
        "\n",
        "def find_prob(prefix, stats, fd):\n",
        "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
        "    try:\n",
        "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
        "    except:\n",
        "        prob = 0\n",
        "        fd.write(prefix + \"\\n\")\n",
        "    return prob\n",
        "\n",
        "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
        "    misclassifications = 0\n",
        "    names_processed = 0\n",
        "    for prefix in test_set:\n",
        "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
        "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
        "        if valid_prob != 0 and invalid_prob != 0:\n",
        "            names_processed += 1\n",
        "            if category == \"valid\" and valid_prob < invalid_prob:\n",
        "                misclassifications += 1\n",
        "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
        "                misclassifications += 1\n",
        "    return misclassifications, names_processed\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load valid names training set\n",
        "    valid_names_training = load_file(\"./valid_training.txt\")\n",
        "    # Load valid names test set\n",
        "    valid_names_test = load_file(\"./valid_test.txt\")\n",
        "    # Load invalid names training set\n",
        "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
        "    # Load invalid names test set\n",
        "    invalid_names_test = load_file(\"./invalid_test.txt\")\n",
        "\n",
        "    valid_stats = calculate_probabilities(valid_names_training)\n",
        "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
        "\n",
        "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
        "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
        "\n",
        "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
        "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
            "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n",
            "CPU times: user 30.6 s, sys: 207 ms, total: 30.8 s\n",
            "Wall time: 32.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu6gojV8WGZ9",
        "outputId": "7907b6bb-5b8c-4053-e527-4d6e531886ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: {13: 0.060977142857142855, 6: 0.07845857142857143, 16: 0.03039714285714286, 8: 0.10063142857142857, 10: 0.09508714285714286, 5: 0.05750285714285714, 9: 0.10058, 7: 0.09083285714285715, 11: 0.08423571428571429, 15: 0.040222857142857144, 19: 0.01268857142857143, 21: 0.006614285714285714, 14: 0.050147142857142855, 4: 0.03768571428571429, 12: 0.07327142857142857, 17: 0.023665714285714286, 22: 0.004825714285714286, 3: 0.013177142857142858, 18: 0.017365714285714286, 24: 0.002354285714285714, 20: 0.009247142857142857, 25: 0.0016685714285714285, 23: 0.0032485714285714284, 29: 0.0003928571428571429, 27: 0.0008242857142857142, 28: 0.0005857142857142858, 26: 0.0011357142857142857, 30: 0.0002985714285714286, 2: 0.0009414285714285715, 32: 0.00016714285714285713, 31: 0.00024142857142857142, 39: 2.1428571428571428e-05, 37: 4.428571428571428e-05, 45: 5.7142857142857145e-06, 42: 5.7142857142857145e-06, 35: 6.857142857142857e-05, 33: 0.00010714285714285714, 36: 5.142857142857143e-05, 57: 1.4285714285714286e-06, 34: 8.714285714285714e-05, 40: 1.1428571428571429e-05, 38: 3e-05, 54: 4.2857142857142855e-06, 44: 7.142857142857143e-06, 1: 3.4285714285714284e-05, 53: 1.4285714285714286e-06, 47: 4.2857142857142855e-06, 49: 4.2857142857142855e-06, 41: 1e-05, 48: 5.7142857142857145e-06, 60: 7.142857142857143e-06, 56: 2.8571428571428573e-06, 63: 2.8571428571428573e-06, 46: 2.8571428571428573e-06, 43: 4.2857142857142855e-06, 58: 1.4285714285714286e-06}, 1: {0: 0.92479, 2: 0.02117857142857143, 1: 0.031337142857142855, 3: 0.012788571428571429, 4: 0.006322857142857143, 9: 0.00021428571428571427, 7: 0.0004142857142857143, 8: 0.0003585714285714286, 5: 0.0012357142857142857, 6: 0.0009471428571428571, 13: 3.7142857142857143e-05, 10: 0.00016428571428571428, 12: 6.428571428571429e-05, 11: 8.428571428571429e-05, 21: 1.4285714285714286e-06, 15: 1.2857142857142857e-05, 14: 2.1428571428571428e-05, 19: 1.4285714285714286e-06, 16: 5.7142857142857145e-06, 27: 1.4285714285714286e-06, 40: 1.4285714285714286e-06, 18: 2.8571428571428573e-06, 17: 5.7142857142857145e-06, 47: 1.4285714285714286e-06, 32: 1.4285714285714286e-06, 51: 1.4285714285714286e-06, 42: 1.4285714285714286e-06, 46: 1.4285714285714286e-06, 22: 1.4285714285714286e-06}, 2: {0: 0.92479, 2: 0.02121, 1: 0.033324285714285716, 3: 0.012462857142857144, 4: 0.0061085714285714285, 8: 0.00013857142857142857, 5: 0.0009457142857142857, 6: 0.0006828571428571428, 10: 3.4285714285714284e-05, 7: 0.00022285714285714286, 21: 1.4285714285714286e-06, 9: 4.2857142857142856e-05, 19: 8.571428571428571e-06, 27: 1.4285714285714286e-06, 12: 5.7142857142857145e-06, 17: 2.8571428571428573e-06, 11: 1.2857142857142857e-05, 32: 1.4285714285714286e-06, 13: 1.4285714285714286e-06, 22: 1.4285714285714286e-06}, 3: {8: 0.09587571428571429, 5: 0.15674857142857143, 6: 0.15167285714285714, 9: 0.06849, 4: 0.14074714285714285, 10: 0.04522857142857143, 3: 0.09282142857142857, 7: 0.12562142857142858, 11: 0.028725714285714285, 2: 0.04095571428571428, 16: 0.00176, 1: 0.008004285714285714, 13: 0.010628571428571428, 15: 0.003367142857142857, 0: 0.00338, 12: 0.017754285714285716, 14: 0.005962857142857143, 17: 0.0009757142857142857, 18: 0.0005371428571428571, 19: 0.00031428571428571427, 24: 2e-05, 20: 0.00017285714285714287, 25: 1.1428571428571429e-05, 22: 4.428571428571428e-05, 34: 1.4285714285714286e-06, 21: 0.00011, 28: 2.8571428571428573e-06, 23: 3.4285714285714284e-05, 27: 5.7142857142857145e-06, 26: 1.1428571428571429e-05, 30: 5.7142857142857145e-06, 32: 2.8571428571428573e-06, 63: 1.4285714285714286e-06, 29: 4.2857142857142855e-06}, 4: {2: 0.46264285714285713, 3: 0.27822857142857144, 1: 0.12496428571428571, 6: 0.0069614285714285715, 4: 0.09505, 7: 0.0015028571428571428, 5: 0.026474285714285714, 0: 0.00338, 8: 0.0004557142857142857, 10: 7.714285714285714e-05, 9: 0.00016857142857142857, 11: 4.2857142857142856e-05, 12: 3.4285714285714284e-05, 13: 8.571428571428571e-06, 14: 4.2857142857142855e-06, 16: 1.4285714285714286e-06, 63: 1.4285714285714286e-06, 17: 1.4285714285714286e-06}, 5: {5: 0.1409857142857143, 1: 0.06428714285714286, 6: 0.08624428571428572, 7: 0.04837857142857143, 4: 0.20394571428571429, 0: 0.03543428571428572, 3: 0.22071714285714286, 2: 0.15541428571428573, 8: 0.02441857142857143, 10: 0.004968571428571429, 9: 0.01136857142857143, 11: 0.0022271428571428572, 13: 0.00039428571428571426, 12: 0.0009271428571428572, 14: 0.00015, 15: 7.428571428571429e-05, 23: 2.8571428571428573e-06, 16: 2.7142857142857144e-05, 18: 7.142857142857143e-06, 17: 2.2857142857142858e-05, 21: 1.4285714285714286e-06, 31: 1.4285714285714286e-06, 19: 1.4285714285714286e-06}, 6: {2: 0.35713428571428574, 1: 0.58797, 0: 0.03543428571428572, 3: 0.01809, 4: 0.0012142857142857142, 5: 0.00011857142857142858, 6: 2.4285714285714285e-05, 8: 5.7142857142857145e-06, 15: 1.4285714285714286e-06, 10: 2.8571428571428573e-06, 7: 4.2857142857142855e-06}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "valid_train = pd.read_csv('valid_training.txt', header=None)\n",
        "invalid_train = pd.read_csv('invalid_training.txt', header=None)\n",
        "\n",
        "mean_valid_train = int(valid_train[0].str.len().mean())\n",
        "mean_invalid_train = int(invalid_train[0].str.len().mean())\n",
        "\n",
        "print(f'Το μέσο μήκος συμβολοσειράς για το αρχείο valid_training.txt είναι {mean_valid_train}.')\n",
        "print(f'Το μέσο μήκος συμβολοσειράς για το αρχείο invalid_training.txt είναι {mean_valid_train}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68C82LsRNVxt",
        "outputId": "d77995d0-981a-4b33-a12f-69d0339ec074"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "Το μέσο μήκος συμβολοσειράς για το αρχείο valid_training.txt είναι 10.\n",
            "Το μέσο μήκος συμβολοσειράς για το αρχείο invalid_training.txt είναι 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Θα εκτελέσουμε τον παρακάτω κώδικα για να υπολογίσουμε την ακρίβεια του αλγορίθμου πάνω στο test set για τα valid και τα invalid names"
      ],
      "metadata": {
        "id": "RPNcLyMwgiZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if __name__ == \"__main__\":\n",
        "    # Load valid names training set\n",
        "    valid_names_training = load_file(\"./valid_training.txt\")\n",
        "    # Load valid names test set\n",
        "    valid_names_test = load_file(\"./valid_test.txt\")\n",
        "    # Load invalid names training set\n",
        "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
        "    # Load invalid names test set\n",
        "    invalid_names_test = load_file(\"./invalid_test.txt\")\n",
        "\n",
        "    test_valid_stats = calculate_probabilities(valid_names_test)\n",
        "    test_invalid_stats = calculate_probabilities(invalid_names_test)\n",
        "\n",
        "    test_valid_misclassifications, test_valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", test_valid_stats, test_invalid_stats, problematic1)\n",
        "    test_invalid_misclassifications, test_invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", test_valid_stats, test_invalid_stats, problematic2)\n",
        "\n",
        "    print(\"Valid names misclassified as invalid - Ratio: \", (test_valid_misclassifications / test_valid_names_processed) * 100)\n",
        "    print(\"Invalid names misclassified as valid - Ratio: \", (test_invalid_misclassifications / test_invalid_names_processed) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l3nxs2ygh2i",
        "outputId": "f050aa4f-2c30-4642-a534-ffdbe511cba4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid names misclassified as invalid - Ratio:  3.726564753389097\n",
            "Invalid names misclassified as valid - Ratio:  1.2421115897024941\n",
            "CPU times: user 10.6 s, sys: 211 ms, total: 10.8 s\n",
            "Wall time: 10.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ΑΠΑΝΤΗΣΕΙΣ:"
      ],
      "metadata": {
        "id": "41Po6vGq3Shq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i)\n",
        "\n",
        "Βασική Παραδοχή Naive Bayes Classifier:\n",
        "\n",
        "\n",
        "Στη μηχανική μάθηση, οι απλοί ταξινομητές Bayes είναι μία οικογένεια απλών <<πιθανολογικών ταξινομητών>> που βασίζονται στην εφαρμογή του θεωρήματος Bayes με ισχυρές (ή και αφελής) υποθέσεις , ανεξάρτητες μεταξύ των features(χαρακτηριστικών).\n",
        "\n",
        "Συνεπώς, η βασική παραδοχή του αλγορίθμου Naive Bayes Classifier είναι η υπόθεση της ανεξαρτησίας των χαρακτηριστικών. Συγκεκριμένα, ο αλγόριθμος υποθέτει ότι κάθε χαρακτηριστικό σε ένα δείγμα είναι ανεξάρτητο από τα υπόλοιπα χαρακτηριστικά, δεδομένης της κλάσης στην οποία ανήκει το δείγμα. Αυτή η παραδοχή είναι αρκετά ισχυρή και συχνά μη ρεαλιστική, καθώς τα χαρακτηριστικά στις πραγματικές εφαρμογές συχνά αλληλοεξαρτώνται. Παρ' όλα αυτά, ο Naive Bayes Classifier λειτουργεί αρκετά καλά σε πολλές περιπτώσεις , ακόμα και όταν η παραδοχή της ανεξαρτησίας παραβιάζεται.\n",
        "\n",
        "Για παράδειγμα, στον Naive Bayes , για ένα πρόβλημα κατηγοριοποίησης κειμένου, η πιθανότητα ενός κειμένου να ανήκει σε μία συγκεκριμένη κατηγορία υπολογίζεται με βάση την υπόθεση ότι η παρουσία ή απουσία μίας λέξης είναι ανεξάρτητη από την παρουσία ή την απουσία άλλων λέξεων, δεδομένης της κατηγορίας.\n",
        "\n",
        "Μαθηματικά η παραδοχή αυτή διατυπώνεται ως εξής:\n",
        "\n",
        "P(X1,X2,...,Xn|C)= P(X1|C)* P(X2|C)...*P(Xn|C), όπου\n",
        "\n",
        "x1,x2,...,xn είναι τα χαρακτηριστικά του δείγματος\n",
        "\n",
        "C είναι η κατηγορία στην οποία ανήκει το δείγμα\n",
        "\n",
        "P(Xi|C) είναι η πιθανότητα του χαρακτηριστικού Xi δεδομένης της κατηγορίας C.\n",
        "\n",
        "\n",
        "Πλεονεκτήματα Naive Bayes Classifier:\n",
        "\n",
        "1. Εφαρμόζεται εύκολα και είναι υπολογιστικά αποδοτικός\n",
        "2. Αποτελεσματικός σε περιπτώσεις με μεγάλο αριθμό από features\n",
        "3. Αποδίδει πολύ καλά ακόμη και όταν έχουμε περιορισμένα training data\n",
        "4. Αντιδράει καλά και αποδίδει αποτελεσματικά στην παρουσία κατηγορηματικών features\n",
        "5. Στον αλγόριθμο αυτό, τα features με αριθμιτικά δεδομένα προέρχονται από κανονική κατανομή.\n",
        "\n",
        "Εφαρμογές Naive Bayes Classifier:\n",
        "\n",
        "1. Spam Email Filtering: Χωρίζει τα email σε spam ή non-spam με βάση τα features\n",
        "2. Text Classification: Χρησιμοποιείται για ανάλυση συναισθήματος στα κείμενα, κατηγοριοποίησης document και διαχωρισμό θεμάτων.\n",
        "3. Medical Diagnosis: Βοηθάει στη πρόβλεψη της πιθανότητας κάποιας ασθένειας με βάση κάποια συμπτώματα\n",
        "4. Weather Prediction: Κατηγοριοποιεί τις καιρικές συνθήκες με βάση διάφορους παράγοντες\n",
        "5. Credit Scoring: Μπορεί να αξιολογήσει τη πιστοληπτική ικανότητα των ατόμων για την έγκριση του δανείου."
      ],
      "metadata": {
        "id": "mLWh2Evz3X6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii)\n",
        "\n",
        "Το θεώρημα Bayes βρίσκει τη πιθανότητα να συμβεί ένα γεγονός δεδομένης της πιθανότητας ενός άλλου γεγονότος που έχει ήδη συμβεί. Το θεώρημα του Bayes δηλώνεται μαθηματικά ως η ακόλουθη εξίσωση:\n",
        "\n",
        "P(A|B)=P(B|A)*P(A)/P(B), όπου Α και Β είναι γεγονότα και P(B)!=0\n",
        "\n",
        "Στην ουσία προσπαθούμε να βρούμε τη πιθανότητα του γεγονότος Α , δεδομένου ότι το γεγονός Β είναι αληθές. Το συμβάν Β ορίζεται επίσης ως αποδεικτικό στοιχείο.\n",
        "\n",
        "Το P(A) είναι η προηγούμενη πιθανότητα, δηλαδή η πιθανότητα πριν εμφανιστεί το αποδεικτικό στοιχείο. Η απόδειξη είναι μία τιμή χαρακτηριστικού ενός αγνώστου στιγμιότυπου (εδώ είναι το συμβάν Β).\n",
        "\n",
        "Το P(B) είναι η οριακή πιθανότητα. Πιθανότητα Απόδειξης\n",
        "\n",
        "Το P(A|B) είναι μία εκ των υστέρων πιθανότητα του Β, δηάδή η πιθανότητα συμβάντος μετά την εμφάνιση στοιχείων.\n",
        "\n",
        "Το P(B|A) είναι η πιθανότητα η υπόθεση να βγει αληθινή με βάση το αποδεικτικό στοιχείο.\n",
        "\n",
        "Γενικά έχουμε ότι:\n",
        "1. Συλλέγουμε τα δεδομένα εκπαίδευσης και τα χωρίζουμε σε διαφορετικές κλάσεις\n",
        "2. Υπολογίζουμε τις απαραίτητες πιθανότητες από τα δεδομένα εκπαίδευσης\n",
        "3. Για ένα νέο δείγμα, υπολογίζουμε τη πιθανότητα για κάθε κλάση\n",
        "4. Κατατάσουμε το δείγμα στη κλάση με τη μεγαλύτερη πιθανότητα\n",
        "\n",
        "\n",
        "Εκπαίδευση:\n",
        "\n",
        "Υπολογίζουμε τις αρχικές πιθανότητες P(C) για κάθε κατηγορία C.\n",
        "Υπολογίζουμε τις πιθανότητες P(Xi∣C) για κάθε χαρακτηριστικό Xi δεδομένης της κατηγορίας C.\n",
        "Ταξινόμηση:\n",
        "\n",
        "Για ένα νέο δείγμα χαρακτηριστικών 𝑋={𝑋1,𝑋2,...,𝑋𝑛}\n",
        ", υπολογίζουμε την πιθανότητα κάθε κατηγορίας C με βάση το προϊόν των πιθανοτήτων των χαρακτηριστικών: 𝑃(𝐶∣𝑋)∝𝑃(𝐶)⋅𝑃(𝑋1∣𝐶)⋅𝑃(𝑋2∣𝐶)⋅.. (𝑋𝑛∣𝐶). Επιλέγουμε την κατηγορία με τη μέγιστη πιθανότητα.\n",
        "\n",
        "Παραδοχές Naive Bayes:\n",
        "1. Ανεξαρτησία χαρακτηριστικών: Τα χαρακτηριστικά (features) των δεδομένων είναι υπό όρους ανεξάρτητα μεταξύ τους, δεδομένου της ετικέτας κλάσης (label class)\n",
        "2. Τα συνεχή χαρακτηριστικά κατανέμονται κανονικά: Εάν ένα χαρακτηριστικό είναι συνεχές , τότε θεωρείται ότι είναι κανονικά κατανεμημένο σε κάθε κλάση\n",
        "3. Τα διακριτά χαρακτηριστικά έχουν πολυωνυμικές κατανομές: Εάν ένα χαρακτηριστικό είναι διακριτό , τότε θεωρείται ότι έχει πολυωνυμική κατανομή\n",
        "σε κάθε κλάση\n",
        "4. Όλα τα χαρακτηριστικά είναι εξίσου σημαντικά, δηλαδή συμβάλουν εξίσου στη πρόβλεψη του label class (y)\n",
        "5. Δεν λείπουν δεδομένα: Τα δεδομένα δεν πρέπει να περιέχουν τιμές που λείπουν."
      ],
      "metadata": {
        "id": "bIj-HVM55HM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii)"
      ],
      "metadata": {
        "id": "DOdUG5CVsifi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "valid_training = 'valid_training.txt'\n",
        "invalid_training = 'invalid_training.txt'\n",
        "\n",
        "# Function to read lines from a file\n",
        "def read_lines(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.readlines()\n",
        "\n",
        "# Function to extract prefixes from lines\n",
        "def extract_prefixes(lines, prefix_length=3):\n",
        "    return [line[:prefix_length] for line in lines]\n",
        "\n",
        "\n",
        "# Function to count prefix frequencies\n",
        "def count_prefixes(prefixes):\n",
        "    return Counter(prefixes)\n",
        "\n",
        "\n",
        "\n",
        "valid_lines = read_lines(valid_training)\n",
        "invalid_lines = read_lines(invalid_training)\n",
        "\n",
        "\n",
        "prefix_length = 3\n",
        "valid_prefixes = extract_prefixes(valid_lines, prefix_length)\n",
        "invalid_prefixes = extract_prefixes(invalid_lines, prefix_length)\n",
        "\n",
        "# Count prefix frequencies\n",
        "valid_prefix_counter = count_prefixes(valid_prefixes)\n",
        "invalid_prefix_counter = count_prefixes(invalid_prefixes)\n",
        "\n",
        "\n",
        "print(\"Most common prefixes in valid dataset\")\n",
        "counter=0\n",
        "valid_prefix_counter={k: v for k, v in sorted(valid_prefix_counter.items(), key=lambda item: item[1],reverse=True)}\n",
        "for prefix in valid_prefix_counter:\n",
        "  print(f\"{prefix}:{valid_prefix_counter[prefix]}\")\n",
        "  counter+=1\n",
        "  if (counter==10):\n",
        "    break\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"Most common prefixes in invalid dataset\")\n",
        "c=0\n",
        "invalid_prefix_counter={k: v for k, v in sorted(invalid_prefix_counter.items(), key=lambda item: item[1],reverse=True)}\n",
        "for prefix in invalid_prefix_counter:\n",
        "  print(f\"{prefix}:{invalid_prefix_counter[prefix]}\")\n",
        "  c+=1\n",
        "  if (c==10):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r2_mlFRsjqt",
        "outputId": "97989dde-9e0e-4fa4-cf39-54d8d3d3d563"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common prefixes in valid dataset\n",
            "the:8300\n",
            "pro:3931\n",
            "fre:2818\n",
            "tra:2734\n",
            "por:2496\n",
            "con:2410\n",
            "com:2303\n",
            "mar:2276\n",
            "car:2269\n",
            "sta:2189\n",
            "\n",
            "\n",
            "\n",
            "Most common prefixes in invalid dataset\n",
            "q8i:31\n",
            "8o9:30\n",
            "2yk:30\n",
            "clp:30\n",
            "kyi:30\n",
            "96f:30\n",
            "3y4:30\n",
            "sr0:30\n",
            "1cn:30\n",
            "rpn:29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "iv)\n",
        "\n",
        "Τα 7 features που χρησιμοποιούνται είναι:\n",
        "\n",
        "1. total_length\n",
        "2. total_digits\n",
        "3. total_consonats\n",
        "4. total_vowels\n",
        "5. max_numeric_sequence\n",
        "6. max_consonats_sequence\n",
        "7. max_vowels_sequence\n",
        "\n",
        "Το  total length αντιπροσοπεύει το μήκος κάθε συμβολοσειράς.\n",
        "\n",
        "Το total digits αντικατοπτρίζει το σύνολο των χαρακτήρων (strings) της συμβολοσειράς που αντιστοιχούν σε ψηφία (0,1,2,3,4,5,6,7,8,9).\n",
        "\n",
        "Το total_consonats δείχνει το σύνολο των συμφώνων της συμβολοσειράς\n",
        "\n",
        "Το total_vowels δείχνει το σύνολο των φωνήεν της συμβολοσειράς\n",
        "\n",
        "Το max_numeric_sequence δείχνει το μέγιστο πλήθος ψηφίων που εμφανίζονται σε μία συμβολοσειρά\n",
        "\n",
        "Το max_consonats_sequence δείχνει το μέγιστο πλήθος συμφώνων που εμφανίζονται σε κάποια συμβολοσειρά του δείγματος\n",
        "\n",
        "Το max_vowel_sequence δείχνει το μέγιστο πλήθος φωνήεν που εμφανίζονται σε κάποια συμβολοσειρά του δείγματος\n"
      ],
      "metadata": {
        "id": "ynO882cz2N4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "v)\n",
        "\n",
        "Χρησιμοποιώντας την εντολή %%time βλέπουμε ότι ο χρόνος εκπαίδευσης του αλγορίθμου είναι:\n",
        "\n",
        "CPU times: user 10.6 s, sys: 211 ms, total: 10.8 s\n",
        "\n",
        "Wall time: 10.9 s\n",
        "\n",
        "Τόσο όσον αφορα την ακρίβεια του αλγορίθμου καταλήγουμε στα εξής συμπεράσματα:\n",
        "\n",
        "Valid names misclassified as invalid - Ratio:  3.726564753389097\n",
        "\n",
        "\n",
        "Η πολύ υψηλή τιμή αυτής της αναλογίας μας προβληματίζει διότι αυτό σημαίνει   ότι το σύστημα  απορρίπτει πολλά έγκυρα ονόματα. Αυτό μπορεί να έχει αρνητικές επιπτώσεις, διότι χάνουμε ένα αρκετά μεγάλο αριθμό ονομάτων ως μη έγκυρα.\n",
        "\n",
        "Invalid names misclassified as valid - Ratio:  1.2421115897024941\n",
        "\n",
        "Αυτή η τιμή υποδηλώνει ότι το σύστημα κάνει επίσης λάθη αποδεχόμενο άκυρα ονόματα, αν και όχι τόσο συχνά όσο απορρίπτει έγκυρα ονόματα. Αυτό μπορεί να οδηγήσει σε προβλήματα με την ακεραιότητα των δεδομένων και την ασφάλεια.\n",
        "\n",
        "\n",
        "Το μέγεθος του training set είναι:"
      ],
      "metadata": {
        "id": "9lh2MYr-NVoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(valid_names_training)+len(invalid_names_training))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHizZzhWkw3Q",
        "outputId": "2e5b1a5d-3c54-4e85-cbb5-ad79034d85ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vi)\n",
        "\n",
        "Τα μειονεκτήματα του αλγορίθμου Naive Bayes είναι τα εξής:\n",
        "\n",
        "1. Ο αλγόριθμος υποθέτει ότι τα χαρακτηριστικά είναι ανεξάρτητα, τα οποία μπορεί να μην ισχύουν πάντα σε δεδομένα πραγματικού κόσμου.\n",
        "2. Μπορεί να επηρεαστεί από άσχετα χαρακτηριστικά.\n",
        "3. Μπορεί να εκχωρήσει μηδενική πιθανότητα σε μη ορατά γεγονότα, οδηγώντας σε κακή γενίκευση.\n",
        "\n",
        "Τα 2 αρχεία που δημιουργούνται (problematic_valid.txt και problematic_invalid.txt) δημιουργούν το πρόβλημα της μηδενικής συχνότητας (zero frequency problem). Το πρόβλημα αυτό προκύπτει κατά τη χρήση του ταξινομητή Naive Bayes όταν ένα συγκεκριμένο feature (χαρακτηριστικό) δεν εμφανίζεται σε κανένα παράδειγμα εκπαίδευσης για μια δεδομένη κατηγορία. Αυτό σημαίνει ότι η πιθανότητα εμφάνισης αυτού του feature για την κατηγορία αυτή θα είναι μηδενική, κάτι που μπορεί να οδηγήσει σε ανεπιθύμητα αποτελέσματα κατά την ταξινόμηση νέων δεδομένων.\n",
        "\n",
        "Πιο συγκεκριμένα, στον ταξινομητή Naive Bayes, οι πιθανότητες των χαρακτηριστικών πολλαπλασιάζονται για να υπολογιστεί η συνολική πιθανότητα μιας κατηγορίας. Εάν οποιοδήποτε χαρακτηριστικό έχει πιθανότητα μηδέν, η συνολική πιθανότητα για αυτή την κατηγορία θα είναι επίσης μηδέν, ανεξάρτητα από τις άλλες πιθανότητες. Αυτό μπορεί να οδηγήσει σε λανθασμένες ταξινομήσεις, καθώς η κατηγορία με πιθανότητα μηδέν θα απορριφθεί αυτόματα.\n",
        "\n",
        "\n",
        "Μια προσέγγιση για να ξεπεραστεί αυτό το «πρόβλημα μηδενικής συχνότητας» είναι να προσθέσουμε +1 στο πλήθος για κάθε συνδυασμό τιμής χαρακτηριστικού-κλάσης όταν η τιμή ενος feature δεν εμφανίζεται με κάθε τιμή της κλάσης.\n",
        "\n",
        "Αυτό θα οδηγήσει στην αφαίρεση όλων των μηδενικών τιμών από τις κλάσεις και, ταυτόχρονα, δεν θα επηρεάσει τη συνολική σχετική συχνότητα των κλάσεων.\n",
        "\n",
        "Αυτή η διαδικασία «εξομάλυνσης» των δεδομένων μας με την προσθήκη ενός αριθμού είναι γνωστή ως additive smoothing (εξομάλυνση προσθέτων) , που ονομάζεται επίσης εξομάλυνση Laplace (Laplace smoothing)."
      ],
      "metadata": {
        "id": "uoL9seMPLhxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "vii)\n",
        "\n",
        "\n",
        "Η συνάρτηση find_prob()  στον ταξινομητή Naive Bayes βασίζεται σε πιθανότητες που υπολογίζονται από τα δεδομένα εκπαίδευσης. Αν δεν λαμβάνουμε υπόψη τις prior πιθανότητες, τότε αυτό σημαίνει ότι έχουμε κάνει την παραδοχή ότι οι δύο κατηγορίες (valid και invalid) έχουν ίσες πιθανότητες εμφάνισης. Αυτή είναι μια απλοποίηση που μπορεί να μην ισχύει πάντα στην πραγματικότητα.\n",
        "\n",
        "\n",
        "Η παραδοχή λοιπόν, είναι ότι οι prior πιθανότητες είναι ίσες ( 0.5 για κάθε κατηγορία) από τη στιγμή κιόλας που το μέγεθος των δύο συνόλων εκπαίδευσης (ένα για valid και ένα για invalid) είναι κοινό (700.000 συμβολοσειρές έκοστος). Το γεγονός αυτό απλοποιεί τους υπολογισμούς και σημαίνει ότι θεωρούμε πως δεν υπάρχει προκατάληψη υπέρ κάποιας κατηγορίας πριν δούμε τα δεδομένα. Αυτό μπορεί να λειτουργήσει καλά σε περιπτώσεις όπου οι κατηγορίες είναι περίπου ισοκατανεμημένες.\n",
        "\n",
        " Υπάρχουν διάφορες εναλλακτικές για την εκτίμηση των prior πιθανοτήτων, μέσω αλγορίθμων που εκτιμούν γενικά παραμέτρους στατιστικών κατανομών, δεδομένου ενός δειγματικού συνόλου. Ο γνωστότερος εξ αυτών είναι μάλλον ο αλγόριθμος Maximum Likelihood Estimation (MLE)."
      ],
      "metadata": {
        "id": "67xi6QI-OEH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "viii)\n",
        "\n",
        "Ένα επιπλέον feature που θα μπορούσαμε να προσθέσουμε στον αλγόριθμο είναι να υπολογίζει από ποιο string αρχίζουν οι μεγαλύτερες λέξεις και από ποιο οι μικρότερες.\n",
        "\n",
        "Επίσης ένα άλλο κατά τη γνώμη μου χρήσιμο feature  θα ήταν αν υπολόγιζε ο αλγόριθμος το μέσο μήκος των λέξεων που περιέχουν sting αριθμό(0,1,2,3,4,5,6,7,8,9) και τι μέσο μήκος οι λέξεις που δεν περιέχουν string αριθμό."
      ],
      "metadata": {
        "id": "C6ExVs1eXUvZ"
      }
    }
  ]
}